{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyM4udvEgnYsLZjxhnAG0Hxp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"eEiU6OxQLqhG","executionInfo":{"status":"ok","timestamp":1741719659988,"user_tz":420,"elapsed":23,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpCHkuohLwPR","executionInfo":{"status":"ok","timestamp":1741719660764,"user_tz":420,"elapsed":769,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}},"outputId":"478bafb5-059c-466e-de19-4cc8e4b9904a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"Raffaello_Sanzio/styleid\"\n","GOOGLE_DRIVE_PATH = os.path.join('/content/drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7zd6puQLxgA","executionInfo":{"status":"ok","timestamp":1741719660769,"user_tz":420,"elapsed":3,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}},"outputId":"ee510483-bda1-476a-eed0-7119d276b34e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['ckpt', 'data', 'data_model', 'config', 'ldm', 'models', 'output', 'precomputed_feats', 'IMG_3724.JPG', 'IMG_3724_styled_joana-abreu-aFkzShngdaw-unsplash.png', 'lora', 'train', 'styleid.ipynb', 'train.ipynb']\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)"],"metadata":{"id":"nOgugvxAL6CI","executionInfo":{"status":"ok","timestamp":1741719660770,"user_tz":420,"elapsed":1,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch-lightning==1.4.2\n","!pip install omegaconf==2.1.1\n","!pip install torchmetrics==0.6.0\n","!pip install git+https://github.com/openai/CLIP.git\n","!pip install kornia==0.6"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"x0-DUL71pcqH","executionInfo":{"status":"ok","timestamp":1741719674811,"user_tz":420,"elapsed":14040,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}},"outputId":"b5ed889a-7498-4eb4-fa25-b3f873825b4e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytorch-lightning==1.4.2 in /usr/local/lib/python3.11/dist-packages (1.4.2)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (1.26.4)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (2.5.1+cu124)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (1.0.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (6.0.2)\n","Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (2024.10.0)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (2.18.0)\n","Requirement already satisfied: torchmetrics>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (0.6.0)\n","Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (0.3.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (24.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.4.2) (4.12.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (3.11.13)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2) (1.70.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2) (4.25.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2) (3.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->pytorch-lightning==1.4.2) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6->pytorch-lightning==1.4.2) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (2.5.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.4.2) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2) (3.10)\n","Requirement already satisfied: omegaconf==2.1.1 in /usr/local/lib/python3.11/dist-packages (2.1.1)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.1.1) (4.8)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.1.1) (6.0.2)\n","Requirement already satisfied: torchmetrics==0.6.0 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==0.6.0) (1.26.4)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==0.6.0) (2.5.1+cu124)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchmetrics==0.6.0) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.1->torchmetrics==0.6.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.1->torchmetrics==0.6.0) (3.0.2)\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-i6a3l9o5\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-i6a3l9o5\n","  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.5.1+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.20.1+cu124)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n","Requirement already satisfied: kornia==0.6 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from kornia==0.6) (2.5.1+cu124)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia==0.6) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->kornia==0.6) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->kornia==0.6) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->kornia==0.6) (3.0.2)\n"]}]},{"cell_type":"code","source":["import os\n","import yaml\n","import argparse\n","import time\n","import copy\n","import torch\n","import numpy as np\n","import pickle\n","from contextlib import nullcontext\n","from PIL import Image\n","from torchvision import transforms\n","from einops import rearrange\n","from pytorch_lightning import seed_everything\n","from peft import PeftModel\n","\n","from ldm.util import instantiate_from_config\n","from ldm.models.diffusion.ddim import DDIMSampler"],"metadata":{"id":"nSJz2J9dRQM6","executionInfo":{"status":"ok","timestamp":1741719683988,"user_tz":420,"elapsed":9175,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def load_model_from_config(model_config, ckpt_path, lora_path, verbose=False, load_lora=False):\n","    print(f\"Loading model from {ckpt_path}\")\n","    pl_sd = torch.load(ckpt_path, map_location=\"cpu\")\n","    if \"global_step\" in pl_sd:\n","        print(f\"Global Step: {pl_sd['global_step']}\")\n","    sd = pl_sd[\"state_dict\"]\n","    model = instantiate_from_config(model_config[\"model\"])\n","    m, u = model.load_state_dict(sd, strict=False)\n","    if len(m) > 0 and verbose:\n","        print(\"missing keys:\")\n","        print(m)\n","    if len(u) > 0 and verbose:\n","        print(\"unexpected keys:\")\n","        print(u)\n","\n","    # load lora\n","    if load_lora:\n","        print(f\"Loading LoRA from {lora_path}\")\n","        model.model.diffusion_model = PeftModel.from_pretrained(model.model.diffusion_model, lora_path)\n","        # print(model.model.diffusion_model)\n","    model.cuda()\n","    model.eval()\n","    return model"],"metadata":{"id":"VGfN1yM1mRU9","executionInfo":{"status":"ok","timestamp":1741719684014,"user_tz":420,"elapsed":19,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def load_img(path):\n","    im = Image.open(path).convert(\"RGB\")\n","    x, y = im.size\n","    print(f\"Loaded input image of size ({x}, {y}) from {path}\")\n","    h = w = 512\n","    im = transforms.CenterCrop(min(x,y))(im)\n","    im = im.resize((w,h), resample=Image.Resampling.LANCZOS)\n","    im = np.array(im).astype(np.float32) / 255.0\n","    im = im[None].transpose(0, 3, 1, 2)\n","    im = torch.from_numpy(im)\n","    return 2. * im - 1."],"metadata":{"id":"406qFsioNZNh","executionInfo":{"status":"ok","timestamp":1741719684069,"user_tz":420,"elapsed":54,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def adain(cnt_feat, sty_feat):\n","    cnt_mean = cnt_feat.mean(dim=[0,2,3], keepdim=True)\n","    cnt_std = cnt_feat.std(dim=[0,2,3], keepdim=True )\n","    sty_mean = sty_feat.mean(dim=[0,2,3], keepdim=True)\n","    sty_std = sty_feat.std(dim=[0,2,3], keepdim=True)\n","    return ((cnt_feat - cnt_mean) / cnt_std) * sty_std + sty_mean"],"metadata":{"id":"eQk1mxd3zWaC","executionInfo":{"status":"ok","timestamp":1741719684129,"user_tz":420,"elapsed":52,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def feat_merge(train_config, cnt_feats, sty_feats, start_step):\n","    feat_maps = [\n","        {\n","            \"config\" :{\n","                \"gamma\" : train_config[\"gamma\"],\n","                \"T\" : train_config[\"T\"],\n","            }\n","        } for _ in range(50)\n","    ]\n","\n","    for i in range(len(feat_maps)):\n","        if i < (50 - start_step):\n","            continue\n","        cnt_feat = cnt_feats[i]\n","        sty_feat = sty_feats[i]\n","        ori_keys = sty_feat.keys()\n","\n","        for ori_key in ori_keys:\n","            if ori_key[-1] == 'q':\n","                feat_maps[i][ori_key] = cnt_feat[ori_key]\n","            if ori_key[-1] == 'k' or ori_key[-1] == 'v':\n","                feat_maps[i][ori_key] = sty_feat[ori_key]\n","    return feat_maps\n"],"metadata":{"id":"9pU4vWg14FSv","executionInfo":{"status":"ok","timestamp":1741719684210,"user_tz":420,"elapsed":76,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def train(args):\n","    with open(args.config_path) as f:\n","        config = yaml.safe_load(f)\n","\n","    train_config = config[\"train_params\"]\n","\n","    seed = train_config[\"seed\"]\n","    seed_everything(22)\n","    feat_path_root = train_config[\"precomputed\"]\n","\n","    output_path = os.path.join(GOOGLE_DRIVE_PATH, train_config[\"output_path\"])\n","    os.makedirs(output_path, exist_ok=True)\n","    if len(feat_path_root):\n","        os.makedirs(os.path.join(GOOGLE_DRIVE_PATH, feat_path_root), exist_ok=True)\n","\n","    with open(os.path.join(GOOGLE_DRIVE_PATH, train_config[\"model_config\"])) as f:\n","        model_config = yaml.safe_load(f)\n","\n","    ckpt_path = os.path.join(GOOGLE_DRIVE_PATH, train_config[\"ckpt\"])\n","    lora_path = os.path.join(GOOGLE_DRIVE_PATH, \"lora\", train_config[\"lora_ckpt_name\"])\n","    use_lora = False\n","\n","    model = load_model_from_config(model_config, ckpt_path, lora_path, load_lora=use_lora)\n","\n","    self_attn_output_block_indices = list(map(int, train_config[\"attn_layer\"].split(',')))\n","    ddim_inversion_steps = train_config[\"ddim_inv_steps\"]\n","    save_feature_timesteps = ddim_steps = train_config[\"save_feat_steps\"]\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    unet_model = model.model.diffusion_model\n","\n","    # scheduler\n","    sampler = DDIMSampler(model)\n","    sampler.make_schedule(ddim_num_steps=ddim_steps, ddim_eta=train_config[\"ddim_eta\"], verbose=False)\n","    time_range = np.flip(sampler.ddim_timesteps)\n","    idx_time_dict = {}\n","    time_idx_dict = {}\n","    for i, t in enumerate(time_range):\n","        idx_time_dict[t] = i\n","        time_idx_dict[i] = t\n","\n","    seed = torch.initial_seed()\n","    train_config[\"seed\"] = seed\n","    print(f\"Init Seed: {seed}\")\n","\n","    global feat_maps\n","    feat_maps = [\n","        {\n","            \"config\" :{\n","                \"gamma\" : train_config[\"gamma\"],\n","                \"T\" : train_config[\"T\"],\n","            }\n","        } for _ in range(50)\n","    ]\n","\n","    def ddim_sampler_callback(pred_x0, xt, i):\n","        save_feature_maps_callback(i)\n","        save_feature_map(xt, 'z_enc', i)\n","\n","    def save_feature_maps_callback(i):\n","        save_feature_maps(unet_model.output_blocks, i, \"output_block\")\n","\n","    def save_feature_maps(blocks, i, feature_type=\"input_block\"):\n","        block_idx = 0\n","        for block_idx, block in enumerate(blocks):\n","            if len(block) > 1 and \"SpatialTransformer\" in str(type(block[1])):\n","                if block_idx in self_attn_output_block_indices:\n","                    q = block[1].transformer_blocks[0].attn1.q\n","                    k = block[1].transformer_blocks[0].attn1.k\n","                    v = block[1].transformer_blocks[0].attn1.v\n","                    save_feature_map(q, f\"{feature_type}_{block_idx}_self_attn_q\", i)\n","                    save_feature_map(k, f\"{feature_type}_{block_idx}_self_attn_k\", i)\n","                    save_feature_map(v, f\"{feature_type}_{block_idx}_self_attn_v\", i)\n","\n","    def save_feature_map(feature_map, filename, time):\n","        global feat_maps\n","        cur_idx = idx_time_dict[time]\n","        feat_maps[cur_idx][f\"{filename}\"] = feature_map\n","\n","    start_step = train_config[\"start_step\"]\n","    precision_scope = torch.autocast if train_config[\"precision\"] == \"autocast\" else nullcontext\n","\n","    c = model.get_learned_conditioning([\"Raffaello Sanzio Painting\"]) if use_lora else None\n","    # c = None\n","    uc = model.get_learned_conditioning([\"\"])\n","    shape = [train_config['C'], train_config['H'] // train_config['f'], train_config['W'] // train_config['f']]\n","    sty_img_list = sorted(os.listdir(os.path.join(GOOGLE_DRIVE_PATH, train_config['sty'])))\n","    cnt_img_list = sorted(os.listdir(os.path.join(GOOGLE_DRIVE_PATH, train_config['cnt'])))\n","\n","    begin = time.time()\n","\n","    for sty_name in sty_img_list:\n","        sty_name_ = os.path.join(GOOGLE_DRIVE_PATH, train_config['sty'], sty_name)\n","        init_sty = load_img(sty_name_).to(device)\n","        seed = -1\n","        sty_title = os.path.basename(sty_name).split('.')[0]\n","        sty_feat_name = os.path.join(GOOGLE_DRIVE_PATH, feat_path_root,\n","                                     sty_title + \"_sty.pkl\")\n","        sty_z_enc = None\n","\n","        if len(feat_path_root) > 0 and os.path.isfile(sty_feat_name):\n","            print(\"precomputed style Feature found and loading:\", sty_feat_name)\n","            with open(sty_feat_name, 'rb') as h:\n","                sty_feat = pickle.load(f)\n","                sty_z_enc = torch.clone(sty_feat[0]['z_enc'])\n","        else:\n","            init_sty = model.get_first_stage_encoding(model.encode_first_stage(init_sty))\n","            sty_z_enc, _ = sampler.encode_ddim(\n","                init_sty.clone(),\n","                num_steps=ddim_inversion_steps,\n","                conditioning=c,\n","                unconditional_conditioning=uc,\n","                end_step=time_idx_dict[ddim_inversion_steps-1-start_step],\n","                callback_ddim_timesteps=save_feature_timesteps,\n","                img_callback=ddim_sampler_callback\n","            )\n","            sty_feat = copy.deepcopy(feat_maps)\n","            sty_z_enc = feat_maps[0]['z_enc']\n","\n","        for cnt_name in cnt_img_list:\n","            cnt_name_ = os.path.join(GOOGLE_DRIVE_PATH, train_config['cnt'], cnt_name)\n","            init_cnt = load_img(cnt_name_).to(device)\n","\n","            cnt_title = os.path.basename(cnt_name).split('.')[0]\n","            cnt_feat_name = os.path.join(GOOGLE_DRIVE_PATH, feat_path_root,\n","                                         cnt_title + \"_cnt.pkl\")\n","            cnt_z_enc = None\n","\n","            if len(feat_path_root) > 0 and os.path.isfile(cnt_feat_name):\n","                print(\"Precomputed content feature loading: \", cnt_feat_name)\n","                with open(cnt_feat_name, 'rb') as h:\n","                    cnt_feat = pickle.load(h)\n","                    cnt_z_enc = torch.clone(cnt_feat[0]['z_enc'])\n","            else:\n","                init_cnt = model.get_first_stage_encoding(model.encode_first_stage(init_cnt))\n","                cnt_z_enc, _ = sampler.encode_ddim(\n","                    init_cnt.clone(),\n","                    num_steps=ddim_inversion_steps,\n","                    conditioning=c,\n","                    unconditional_conditioning=uc,\n","                    end_step=time_idx_dict[ddim_inversion_steps-1-start_step],\n","                    callback_ddim_timesteps=save_feature_timesteps,\n","                    img_callback=ddim_sampler_callback)\n","                cnt_feat = copy.deepcopy(feat_maps)\n","                cnt_z_enc = feat_maps[0]['z_enc']\n","\n","\n","            with torch.no_grad():\n","                with precision_scope(\"cuda\"):\n","                    with model.ema_scope():\n","                        output_name = f\"{cnt_title}_styled_{sty_title}.png\"\n","                        print(f\"Inversion end: {time.time() - begin}\")\n","                        print(train_config[\"without_init_adain\"], train_config[\"without_init_adain\"])\n","                        if train_config[\"without_init_adain\"]:\n","                            adain_z_enc = cnt_z_enc\n","                        else:\n","                            adain_z_enc = adain(cnt_z_enc, sty_z_enc)\n","\n","                        feat_maps = feat_merge(train_config, cnt_feat, sty_feat, start_step=start_step)\n","\n","                        if train_config[\"without_attn_injection\"]:\n","                            feat_maps = None\n","\n","                        samples_ddim, _ = sampler.sample(\n","                            S=ddim_steps,\n","                            batch_size=1,\n","                            shape=shape,\n","                            verbose=False,\n","                            conditioning=c,\n","                            unconditional_conditioning=uc,\n","                            eta=train_config[\"ddim_eta\"],\n","                            x_T=adain_z_enc,\n","                            injected_features=feat_maps,\n","                            start_step=start_step\n","                        )\n","\n","                        # x_samples_ddim = model.decode_first_stage(samples_ddim)\n","                        # x_samples_ddim = torch.clamp((x_samples_ddim + 1) / 2 , -1., 1.)\n","                        # x_samples_ddim = x_samples_ddim.cpu().permute(0,2,3,1).numpy()\n","                        # x_sample = 255 * x_samples_ddim[0]\n","                        # im = Image.fromarray(x_sample.astype(np.uint8))\n","                        # im.save(os.path.join(output_path, output_name))\n","                        x_samples_ddim = model.decode_first_stage(samples_ddim)\n","                        x_samples_ddim = torch.clamp((x_samples_ddim + 1.0) / 2.0, min=0.0, max=1.0)\n","                        x_samples_ddim = x_samples_ddim.cpu().permute(0, 2, 3, 1).numpy()\n","                        x_image_torch = torch.from_numpy(x_samples_ddim).permute(0, 3, 1, 2)\n","                        x_sample = 255. * rearrange(x_image_torch[0].cpu().numpy(), 'c h w -> h w c')\n","                        img = Image.fromarray(x_sample.astype(np.uint8))\n","\n","                        img.save(os.path.join(output_path, output_name))\n","parser = argparse.ArgumentParser()\n"],"metadata":{"id":"bStndMMgmWCc","executionInfo":{"status":"ok","timestamp":1741719684309,"user_tz":420,"elapsed":96,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["args = argparse.Namespace(config_path=os.path.join(GOOGLE_DRIVE_PATH, 'config/style.yaml'))\n","train(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQCOtujJmWeL","executionInfo":{"status":"ok","timestamp":1741719770842,"user_tz":420,"elapsed":86530,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}},"outputId":"35774b76-97d6-4058-ee4b-3a907cf2c150"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.seed:Global seed set to 22\n","<ipython-input-7-5257947e6802>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  pl_sd = torch.load(ckpt_path, map_location=\"cpu\")\n"]},{"output_type":"stream","name":"stdout","text":["Loading model from /content/drive/My Drive/Raffaello_Sanzio/styleid/models/ldm/stable-diffusion-v1/model.ckpt\n","Global Step: 470000\n","LatentDiffusion: Running in eps-prediction mode\n","DiffusionWrapper has 859.52 M params.\n","making attention of type 'vanilla' with 512 in_channels\n","Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n","making attention of type 'vanilla' with 512 in_channels\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Init Seed: 22\n","Loaded input image of size (1920, 1038) from /content/drive/My Drive/Raffaello_Sanzio/styleid/data/sty/howl003.jpg\n","Running DDIM inversion with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["\rDDIM Inversion:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Selected timesteps for ddim sampler: [  1  21  41  61  81 101 121 141 161 181 201 221 241 261 281 301 321 341\n"," 361 381 401 421 441 461 481 501 521 541 561 581 601 621 641 661 681 701\n"," 721 741 761 781 801 821 841 861 881 901 921 941 961 981]\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Inversion: 100%|██████████| 50/50 [00:08<00:00,  5.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded input image of size (1200, 630) from /content/drive/My Drive/Raffaello_Sanzio/styleid/data/cnt/one.jpg\n","Running DDIM inversion with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["\rDDIM Inversion:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Selected timesteps for ddim sampler: [  1  21  41  61  81 101 121 141 161 181 201 221 241 261 281 301 321 341\n"," 361 381 401 421 441 461 481 501 521 541 561 581 601 621 641 661 681 701\n"," 721 741 761 781 801 821 841 861 881 901 921 941 961 981]\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Inversion: 100%|██████████| 50/50 [00:08<00:00,  5.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Inversion end: 17.834339141845703\n","False False\n","Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n","Running DDIM Sampling with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Sampler: 100%|██████████| 50/50 [00:05<00:00,  8.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded input image of size (1920, 1038) from /content/drive/My Drive/Raffaello_Sanzio/styleid/data/sty/majo050.jpg\n","Running DDIM inversion with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["\rDDIM Inversion:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Selected timesteps for ddim sampler: [  1  21  41  61  81 101 121 141 161 181 201 221 241 261 281 301 321 341\n"," 361 381 401 421 441 461 481 501 521 541 561 581 601 621 641 661 681 701\n"," 721 741 761 781 801 821 841 861 881 901 921 941 961 981]\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Inversion: 100%|██████████| 50/50 [00:08<00:00,  5.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded input image of size (1200, 630) from /content/drive/My Drive/Raffaello_Sanzio/styleid/data/cnt/one.jpg\n","Running DDIM inversion with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["\rDDIM Inversion:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Selected timesteps for ddim sampler: [  1  21  41  61  81 101 121 141 161 181 201 221 241 261 281 301 321 341\n"," 361 381 401 421 441 461 481 501 521 541 561 581 601 621 641 661 681 701\n"," 721 741 761 781 801 821 841 861 881 901 921 941 961 981]\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Inversion: 100%|██████████| 50/50 [00:08<00:00,  5.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Inversion end: 41.708003520965576\n","False False\n","Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n","Running DDIM Sampling with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Sampler: 100%|██████████| 50/50 [00:05<00:00,  9.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded input image of size (1920, 1038) from /content/drive/My Drive/Raffaello_Sanzio/styleid/data/sty/ponyo033.jpg\n","Running DDIM inversion with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["\rDDIM Inversion:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Selected timesteps for ddim sampler: [  1  21  41  61  81 101 121 141 161 181 201 221 241 261 281 301 321 341\n"," 361 381 401 421 441 461 481 501 521 541 561 581 601 621 641 661 681 701\n"," 721 741 761 781 801 821 841 861 881 901 921 941 961 981]\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Inversion: 100%|██████████| 50/50 [00:08<00:00,  5.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded input image of size (1200, 630) from /content/drive/My Drive/Raffaello_Sanzio/styleid/data/cnt/one.jpg\n","Running DDIM inversion with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["\rDDIM Inversion:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Selected timesteps for ddim sampler: [  1  21  41  61  81 101 121 141 161 181 201 221 241 261 281 301 321 341\n"," 361 381 401 421 441 461 481 501 521 541 561 581 601 621 641 661 681 701\n"," 721 741 761 781 801 821 841 861 881 901 921 941 961 981]\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Inversion: 100%|██████████| 50/50 [00:08<00:00,  5.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Inversion end: 65.3847188949585\n","False False\n","Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n","Running DDIM Sampling with 50 timesteps\n"]},{"output_type":"stream","name":"stderr","text":["DDIM Sampler: 100%|██████████| 50/50 [00:05<00:00,  9.38it/s]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","    testing cases\n","        1. With different text emb during training\n","        2. with out conditioning\n","        3.\n","\"\"\""],"metadata":{"id":"HGW3_BRumvOl","executionInfo":{"status":"ok","timestamp":1741719770907,"user_tz":420,"elapsed":63,"user":{"displayName":"Tom Han","userId":"11398329903292398876"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"ce721d34-e889-4379-8881-dd139ee97a4c"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n    testing cases\\n        1. With different text emb during training\\n        2. with out conditioning\\n        3.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]}]}